{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Experiments LAB - Handwritten Digits Classification\n",
    "\n",
    "This demo is prepared with `Python 3 (PyTorch 1.6 ...)` kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Experiments is a capability of Amazon SageMaker that lets you organize, track, compare, and evaluate your machine learning experiments.\n",
    "\n",
    "Machine learning is an iterative process. You need to experiment with multiple combinations of data, algorithm and parameters, all the while observing the impact of incremental changes on model accuracy. Over time this iterative experimentation can result in thousands of model training runs and model versions. This makes it hard to track the best performing models and their input configurations. It’s also difficult to compare active experiments with past experiments to identify opportunities for further incremental improvements.\n",
    "\n",
    "SageMaker Experiments automatically tracks the inputs, parameters, configurations, and results of your iterations as trials. You can assign, group, and organize these trials into experiments. SageMaker Experiments is integrated with Amazon SageMaker Studio providing a visual interface to browse your active and past experiments, compare trials on key performance metrics, and identify the best performing models.\n",
    "\n",
    "You can track artifacts for experiments, including data sets, algorithms, hyper-parameters, and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs will be automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before/after model training e.g. data pre-processing or post-training model evaluation.\n",
    "\n",
    "The APIs also let you search and browse your current and past experiments, compare experiments, and identify best performing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install/upgrade packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install awscli==1.19.14\n",
    "!{sys.executable} -m pip install sagemaker-experiments==0.1.28\n",
    "!{sys.executable} -m pip install sagemaker==2.25.1\n",
    "\n",
    "# remove tqdm, since it has compabible problem with PyTorch\n",
    "!{sys.executable} -m pip uninstall -y tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sagemaker as sm\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "import sagemaker as sme\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role and S3 bucket, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_sess = boto3.Session()\n",
    "boto_sm = boto_sess.client('sagemaker')\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 bucket and prefix\n",
    "sess = sm.session.Session(boto_sess, boto_sm)\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-experiments/DEMO-mnist-classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will demonstrate SageMaker Experiments capabilities through an MNIST handwritten digits classification example. The experiment will be organized as follow:\n",
    "\n",
    "1. Download and prepare the MNIST dataset.\n",
    "2. Train a Convolutional Neural Network (CNN) Model. Tune the hyper parameter that configures the number of hidden channels in the model. Track the parameter configurations and resulting model accuracy using SageMaker Experiments Python SDK.\n",
    "3. Finally use the search and analytics capabilities of Python SDK to search, compare and evaluate the performance of all model versions generated from model tuning in Step 2.\n",
    "4. We will also see an example of tracing the complete linage of a model version i.e. the collection of all the data pre-processing and training configurations and inputs that went into creating that model version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Download and prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits).\n",
    "\n",
    "We download the MNIST hand written digits dataset, and then apply transformation on each of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/issues/1938\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# download the dataset\n",
    "# this will not only download data to ./mnist folder, but also load and transform (normalize) them\n",
    "train_set = datasets.MNIST('mnist', train=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))]), \n",
    "    download=True)\n",
    "                           \n",
    "test_set = datasets.MNIST('mnist', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "    download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_set.data[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the images in the dataset, we upload it to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sm.Session().upload_data(path='mnist', bucket=bucket, key_prefix=prefix)\n",
    "print('input spec: {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets track the parameters from the data pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=boto_sm) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"normalization_mean\": 0.1307,\n",
    "        \"normalization_std\": 0.3081,\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mnist-dataset\", media_type=\"s3/uri\", value=inputs)\n",
    "    \n",
    "preprocessing_trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : [1] a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or [2] a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or [3] a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "experiment_name = \"sagemaker-workshop-experiments-mnist-classification\"\n",
    "experiment_description = \"SageMaker Workshop - Experiments - Classification of mnist hand-written digits\"\n",
    "\n",
    "try:\n",
    "    print('Experiment already exists, loading it...')\n",
    "    mnist_experiment = Experiment.load(\n",
    "        experiment_name=experiment_name, sagemaker_boto_client=boto_sm)\n",
    "    print('Deleting it...')\n",
    "    mnist_experiment.delete_all('--force')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=experiment_name, \n",
    "    description=experiment_description,\n",
    "    sagemaker_boto_client=boto_sm)\n",
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Experiment\n",
    "Now create a Trial for each training run to track the it's inputs, parameters, and metrics.\n",
    "\n",
    "While training the CNN model on SageMaker, we will experiment with several values for the number of hidden channel in the model. We will create a Trial to track each training job run. We will also add a TrialComponent from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run the following training jobs asynchronously, you may need to increase your resource limit. Otherwise, you can run them sequentially.\n",
    "\n",
    "Note the execution of the following code takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type='ml.c5.xlarge'\n",
    "\n",
    "hidden_channel_trial_name_map = {}\n",
    "\n",
    "\n",
    "for i, num_hidden_channel in enumerate([3, 10, 32]):\n",
    "    # create trial\n",
    "    trial_name = f\"cnn-training-job-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=mnist_experiment.experiment_name,\n",
    "        sagemaker_boto_client=boto_sm,\n",
    "    )\n",
    "    hidden_channel_trial_name_map[num_hidden_channel] = trial_name\n",
    "    \n",
    "    # associate the proprocessing trial component with the current trial\n",
    "    cnn_trial.add_trial_component(preprocessing_trial_component)\n",
    "    \n",
    "    # all input configurations, parameters, and metrics specified in estimator \n",
    "    # definition are automatically tracked\n",
    "    estimator = PyTorch(\n",
    "        entry_point='mnist.py',\n",
    "        source_dir='code', # directory of your training script\n",
    "        role=role,\n",
    "        framework_version='1.6.0',\n",
    "        py_version='py3',\n",
    "        instance_type=instance_type,\n",
    "        instance_count=1,\n",
    "        use_spot_instances=True,\n",
    "        max_run=300,\n",
    "        max_wait=300,\n",
    "        hyperparameters={\n",
    "            'epochs': 2,\n",
    "            'backend': 'gloo',\n",
    "            'hidden_channels': num_hidden_channel,\n",
    "            'dropout': 0.2,\n",
    "            'kernel_size': 5,\n",
    "            'optimizer': 'sgd'\n",
    "        },\n",
    "        metric_definitions=[\n",
    "            {'Name':'train:loss', 'Regex':'Train Loss: (.*?);'},\n",
    "            {'Name':'test:loss', 'Regex':'Test Average loss: (.*?),'},\n",
    "            {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*?)%;'}\n",
    "        ],\n",
    "        enable_sagemaker_metrics=True,\n",
    "    )\n",
    "    \n",
    "    cnn_training_job_name = \"cnn-training-job-{}\".format(int(time.time()))\n",
    "    \n",
    "    # Now associate the estimator with the Experiment and Trial\n",
    "    estimator.fit(\n",
    "        inputs={'training': inputs}, \n",
    "        job_name=cnn_training_job_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": cnn_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n",
    "    \n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto_sess, boto_sm), \n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['test:accuracy'],\n",
    "    parameter_names=['hidden_channels', 'epochs', 'dropout', 'optimizer']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the best (as sorted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling best based on sort in the analytics/dataframe so first is best....\n",
    "best_trial_component_name = trial_component_analytics.dataframe().iloc[0]['TrialComponentName']\n",
    "best_trial_component = TrialComponent.load(best_trial_component_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To isolate and measure the impact of change in hidden channels on model accuracy, we vary the number of hidden channel and fix the value for other hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Optional sections\n",
    "\n",
    "Next let's look at an example of tracing the lineage of a model by accessing the data tracked by SageMaker Experiments for `cnn-training-job-2-hidden-channels` trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto_sess, boto_sm), \n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\": \"Parents.TrialName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": hidden_channel_trial_name_map[3]\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy endpoint for the best training-job / trial component\n",
    "\n",
    "Now we'll create an endpoint for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model_data = best_trial_component.output_artifacts['SageMaker.ModelArtifact'].value\n",
    "env = {'hidden_channels': str(int(best_trial_component.parameters['hidden_channels'])), \n",
    "       'dropout': str(best_trial_component.parameters['dropout']), \n",
    "       'kernel_size': str(int(best_trial_component.parameters['kernel_size']))}\n",
    "model = PyTorchModel(\n",
    "    model_data, \n",
    "    role, \n",
    "    './code/mnist.py', \n",
    "    env=env, \n",
    "    sagemaker_session=sm.Session(sagemaker_client=boto_sm),\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    name=best_trial_component.trial_component_name,\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Once we're doing don't forget to clean up the endpoint to prevent unnecessary billing.\n",
    "\n",
    "> Trial components can exist independent of trials and experiments. You might want keep them if you plan on further exploration. If so, comment out tc.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(experiment):\n",
    "    for trial_summary in experiment.list_trials():\n",
    "        trial = Trial.load(sagemaker_boto_client=boto_sm, trial_name=trial_summary.trial_name)\n",
    "        for trial_component_summary in trial.list_trial_components():\n",
    "            tc = TrialComponent.load(\n",
    "                sagemaker_boto_client=boto_sm,\n",
    "                trial_component_name=trial_component_summary.trial_component_name)\n",
    "            trial.remove_trial_component(tc)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                tc.delete()\n",
    "            except:\n",
    "                # tc is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(.5)\n",
    "        trial.delete()\n",
    "    experiment.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(mnist_experiment)\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
