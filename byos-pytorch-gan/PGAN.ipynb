{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 Amazon SageMaker 托管的推理环境，部署人脸生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "Upgrade packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install --upgrade sagemaker awscli boto3 pandas -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following commands for ```SageMaker Studio``` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tqdm\n",
    "\n",
    "import os\n",
    "os.chdir('/root/ml-on-aws/byos-pytorch-gan')\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained PGAN-CelebAHQ-512 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download [Progressive GAN](https://arxiv.org/abs/1710.10196) pre-trained model [PGAN-CelebAHQ-512](https://pytorch.org/hub/facebookresearch_pytorch-gan-zoo_pgan/) from Torch Hub, which is trained on high-quality celebrity faces \"celebAHQ\" dataset, then create a model artifact `model.tar.gz` and upload it to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "use_gpu = False\n",
    "model_algorithm = 'PGAN'\n",
    "\n",
    "# this model outputs 512 x 512 pixel images\n",
    "model_pretrained_name = 'celebAHQ-512' # 'celebAHQ-256'\n",
    "\n",
    "pgan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                       model_algorithm, model_name=model_pretrained_name,\n",
    "                       pretrained=True, useGPU=use_gpu)\n",
    "\n",
    "# generator network\n",
    "netG = pgan.netG\n",
    "\n",
    "num_latent_dim = 512\n",
    "print(netG.getOutputSize())\n",
    "netG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator model with random noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from networks.PGAN.model_tools import generate_noises, show_multiple_pictures\n",
    "\n",
    "noises = generate_noises(4, num_latent_dim)\n",
    "\n",
    "with torch.no_grad():\n",
    "    images = netG(noises)\n",
    "\n",
    "show_multiple_pictures(images)\n",
    "# print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PGAN model to a `.pth` file, and create a TorchServe archive from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_name = f'model-{model_algorithm}-{model_pretrained_name}-' \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "model_folder = f'./tmp/{model_algorithm}'\n",
    "!mkdir -p {model_folder}\n",
    "\n",
    "input_shape = [1, num_latent_dim]\n",
    "# data_shape = '{\"input0\":[1, 512]}'\n",
    "\n",
    "traced_model = torch.jit.trace(netG.float().eval(), torch.zeros(input_shape).float())\n",
    "# scripted_model = torch.jit.script(model)\n",
    "traced_model.save(f\"{model_folder}/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a compressed tar.gz file from the model.pth file.\n",
    "Amazon SageMaker expects that model and related resources are in a tar.gz file, please check manual [SageMaker SDK (using_pytorch)](https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#create-the-directory-structure-for-your-model-files) for details.\n",
    "<code>\n",
    "model.tar.gz/\n",
    "  |- model.pth\n",
    "  |- code/\n",
    "    |- inference.py\n",
    "    |- requirements.txt  # only for versions 1.3.1 and higher\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./model/*\n",
    "\n",
    "!cp -af {model_folder}/{model_name}.pth ./model/model.pth\n",
    "!cp -af ./networks/PGAN ./model/code\n",
    "!rm -rf ./model/code/__pycache__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(f\"{model_folder}/{model_name}.tar.gz\", 'w:gz') as f:\n",
    "    f.add(f\"./model/model.pth\", arcname=\"model.pth\")\n",
    "    f.add(f\"./model/code\", arcname=\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get current SageMaker session, default S3 bucket, and get a role with SageMaker access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the generated model archive file to Amazon S3\n",
    "Uploads the model to your default Amazon SageMaker S3 bucket under the models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader as s3up\n",
    "\n",
    "s3_model_location = s3up.upload(f\"{model_folder}/{model_name}.tar.gz\", f\"s3://{bucket}/artifacts/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class GanPredictor, with serializer and deserializer for x-npy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "from networks.PGAN.serde import serialize, deserialize\n",
    "\n",
    "content_type = 'application/x-npy'\n",
    "\n",
    "class GanPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, sagemaker_session=sagemaker_session,\n",
    "                         serializer=serialize, deserializer=deserialize,\n",
    "                         content_type=content_type, accept=content_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch model from model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "sm_model = PyTorchModel(model_data=s3_model_location,\n",
    "                     role=role,\n",
    "                     predictor_cls=GanPredictor,\n",
    "                     name=model_name,\n",
    "                     entry_point='inference.py',\n",
    "                     py_version=\"py3\",\n",
    "                     framework_version=\"1.5\",\n",
    "                     sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = f'endpoint-{model_algorithm}-{model_pretrained_name}-' \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "predictor = sm_model.deploy(endpoint_name=endpoint_name,\n",
    "                         instance_type='ml.c5.xlarge',\n",
    "                         initial_instance_count=1)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Let's generate some face images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from networks.PGAN.model_tools import generate_noises, show_multiple_pictures\n",
    "\n",
    "images = []\n",
    "for i in range(0, 2):\n",
    "    noises = generate_noises(1, num_latent_dim)\n",
    "    output = predictor.predict(noises.numpy())\n",
    "    images.extend(output)\n",
    "\n",
    "show_multiple_pictures(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete model and endpoint resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker_inference -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./model/code\n",
    "import json\n",
    "from inference import context\n",
    "from model_tools import generate_noises, show_multiple_pictures\n",
    "from serde import serialize, deserialize\n",
    "import handler\n",
    "%cd ../..\n",
    "\n",
    "ctxt = context(\"./model\")\n",
    "\n",
    "noises = generate_noises(4, dim=512)\n",
    "x = serialize(noises.numpy())\n",
    "\n",
    "output = handler.handle([{'data':x}], ctxt)\n",
    "\n",
    "show_multiple_pictures(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./model/code\n",
    "import json\n",
    "import inference\n",
    "from model_tools import generate_noises, show_multiple_pictures\n",
    "from serde import serialize, deserialize\n",
    "\n",
    "model = inference.model_fn(\"..\")\n",
    "%cd ../..\n",
    "\n",
    "content_type = 'application/x-npy'\n",
    "\n",
    "noises = generate_noises(4, dim=512)\n",
    "noises_serialized = serialize(noises.numpy())\n",
    "\n",
    "input_data = inference.input_fn(noises_serialized, content_type)\n",
    "\n",
    "prediction = inference.predict_fn(input_data, model)\n",
    "images_serialized = inference.output_fn(prediction, content_type)\n",
    "\n",
    "show_multiple_pictures(deserialize(images_serialized, content_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:cn-northwest-1:390780980154:image/pytorch-1.4-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
