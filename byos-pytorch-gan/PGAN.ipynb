{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 托管推理环境，部署人脸生成模型 PGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip sagemaker awscli boto3 pandas -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PGAN-CelebAHQ-512 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download [Progressive GAN](https://arxiv.org/abs/1710.10196) pre-trained model [PGAN-CelebAHQ-512](https://pytorch.org/hub/facebookresearch_pytorch-gan-zoo_pgan/) from Torch Hub, which is trained on high-quality celebrity faces \"celebAHQ\" dataset, then create a model artifact `model.tar.gz` and upload it to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "use_gpu = False\n",
    "model_algorithm = 'PGAN'\n",
    "\n",
    "# this model outputs 512 x 512 pixel images\n",
    "model_pretrained_name = 'celebAHQ-512' # 'celebAHQ-256'\n",
    "\n",
    "pgan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                       model_algorithm, model_name=model_pretrained_name,\n",
    "                       pretrained=True, useGPU=use_gpu)\n",
    "\n",
    "# generator network\n",
    "netG = pgan.netG\n",
    "\n",
    "dim_latent = 512\n",
    "print(netG.getOutputSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator model with 4 new random noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pgan.model_tools import generate_noises, show_multiple_pictures\n",
    "\n",
    "noises = generate_noises(4, dim_latent)\n",
    "\n",
    "with torch.no_grad():\n",
    "    images = netG(noises)\n",
    "\n",
    "show_multiple_pictures(images)\n",
    "# print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PGAN model to a `.pth` file, and create a TorchServe archive from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_name = f'model-{model_algorithm}-{model_pretrained_name}-' \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "model_folder = f'./tmp/{model_algorithm}'\n",
    "!mkdir -p {model_folder}\n",
    "\n",
    "input_shape = [1, dim_latent]\n",
    "# data_shape = '{\"input0\":[1, 512]}'\n",
    "\n",
    "traced_model = torch.jit.trace(netG.float().eval(), torch.zeros(input_shape).float())\n",
    "# scripted_model = torch.jit.script(model)\n",
    "traced_model.save(f\"{model_folder}/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./model/*\n",
    "\n",
    "!cp -af {model_folder}/{model_name}.pth ./model/model.pth\n",
    "!cp -af pgan ./model/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a compressed tar.gz file from the model.pth file, since Amazon SageMaker expects that models are in a tar.gz file. \n",
    "\n",
    "<code>\n",
    "model.tar.gz/\n",
    "|- model.pth\n",
    "|- code/\n",
    "  |- inference.py\n",
    "  |- requirements.txt  # only for versions 1.3.1 and higher\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(f\"{model_folder}/{model_name}.tar.gz\", 'w:gz') as f:\n",
    "    f.add(f\"./model/model.pth\", arcname=\"model.pth\")\n",
    "    f.add(f\"./model/code\", arcname=\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a boto3 session and get specify a role with SageMaker access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the generated model archive file to Amazon S3\n",
    "Uploads the model to your default Amazon SageMaker S3 bucket under the models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_location = sess.upload_data(path=f\"{model_folder}/{model_name}.tar.gz\",\n",
    "                              key_prefix=f\"artifacts/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class PganPredictor, with serializer and deserializer for x-npy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "def serialize(nparray, content_type='application/x-npy'):\n",
    "    from io import BytesIO\n",
    "    import numpy as np\n",
    "\n",
    "    if content_type == 'application/json':\n",
    "        deserialized = json.dumps(nparray.tolist())\n",
    "    else:\n",
    "        array_like = nparray.tolist()\n",
    "        buffer = BytesIO()\n",
    "        np.save(buffer, array_like)\n",
    "        deserialized = buffer.getvalue()\n",
    "\n",
    "    return deserialized\n",
    "\n",
    "\n",
    "def deserialize(serialized, content_type='application/x-npy'):\n",
    "    from io import BytesIO\n",
    "    import numpy as np\n",
    "    from botocore.response import StreamingBody\n",
    "\n",
    "    if isinstance(serialized, StreamingBody):\n",
    "        stream = BytesIO(serialized.read())\n",
    "    else:\n",
    "        stream = BytesIO(serialized)\n",
    "\n",
    "    np_output = np.load(stream, allow_pickle=True)\n",
    "    \n",
    "    return np_output\n",
    "\n",
    "\n",
    "class PganPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, sagemaker_session=sagemaker_session, serializer=serialize, \n",
    "                         deserializer=deserialize, content_type='application/x-npy',\n",
    "                         accept='application/x-npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch model from model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "sm_model = PyTorchModel(model_data=s3_model_location,\n",
    "                     role=role,\n",
    "                     predictor_cls=PganPredictor,\n",
    "                     name=model_name,\n",
    "                     entry_point='inference.py',\n",
    "                     py_version=\"py3\",\n",
    "                     framework_version=\"1.5\",\n",
    "                     sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = f'endpoint-{model_algorithm}-{model_pretrained_name}-' \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "predictor = sm_model.deploy(endpoint_name=endpoint_name,\n",
    "#                          instance_type='local',\n",
    "                         instance_type='ml.c5.xlarge',\n",
    "                         initial_instance_count=1)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Let's test with a cat image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pgan.model_tools import generate_noises, show_multiple_pictures\n",
    "\n",
    "images = []\n",
    "for i in range(0, 2):\n",
    "    noises = generate_noises(1)\n",
    "    output = predictor.predict(noises)\n",
    "    images.append(output[0])\n",
    "\n",
    "show_multiple_pictures(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./model/code\n",
    "import json\n",
    "from inference import context\n",
    "import handler\n",
    "\n",
    "import importlib\n",
    "importlib.reload(handler)\n",
    "\n",
    "ctxt = context(\"..\")\n",
    "\n",
    "noises = generate_noises(4)\n",
    "x = serialize(noises.numpy())\n",
    "\n",
    "output = handler.handle([{'data':x}], ctxt)\n",
    "\n",
    "show_multiple_pictures(output[0])\n",
    "\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./model/code\n",
    "import json\n",
    "import inference\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(inference)\n",
    "\n",
    "noises = generate_noises(4)\n",
    "noises_serialized = serialize(noises.numpy())\n",
    "\n",
    "model = inference.model_fn(\"..\")\n",
    "\n",
    "input_data = inference.input_fn(noises_serialized, 'application/x-npy')\n",
    "\n",
    "prediction = inference.predict_fn(input_data, model)\n",
    "images_serialized = inference.output_fn(prediction, 'application/x-npy')\n",
    "\n",
    "show_multiple_pictures(deserialize(images_serialized))\n",
    "\n",
    "%cd ../.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
