{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/pytorch_GAN_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r pytorch_GAN_zoo/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y pytorch=1.5 torchvision=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "PyTorch 框架的 torchvision.datasets 包提供了QMNIST 数据集，您可以通过如下指令下载 QMNIST 数据集到本地备用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataroot = './data'\n",
    "\n",
    "trainset = datasets.CelebA(root=dataroot, split='train')\n",
    "testset = datasets.CelebA(root=dataroot, split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "Amazon SageMaker 为您创建了一个默认的 Amazon S3 桶，用来存取机器学习工作流程中可能需要的各种文件和数据。 我们可以通过 SageMaker SDK 中 sagemaker.session.Session 类的 default_bucket 方法获得这个桶的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to save your custom code in tar.gz format.\n",
    "s3_custom_code_upload_location = f's3://{bucket}/customcode/byos-pytorch-gan'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "s3_model_artifacts_location = f's3://{bucket}/artifacts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker SDK 提供了操作 Amazon S3 服务的包和类，其中 S3Downloader 类用于访问或下载 S3 里的对象，而 S3Uploader 则用于将本地文件上传至 S3。您将已经下载的数据上传至 Amazon S3，供模型训练使用。模型训练过程不要从互联网下载数据，避免通过互联网获取训练数据的产生的网络延迟，同时也规避了因直接访问互联网对模型训练可能产生的安全风险。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader as s3up\n",
    "\n",
    "s3_data_location = s3up.upload(os.path.join(dataroot, \"QMNIST\"), f\"s3://{bucket}/data/qmnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练执行\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 sagemaker.get_execution_role() 方法，当前笔记本可以得到预先分配给笔记本实例的角色，这个角色将被用来获取训练用的资源，比如下载训练用框架镜像、分配 Amazon EC2 计算资源等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型用的超参数可以在笔记本里定义，实现与算法代码的分离，在创建训练任务时传入超参数，与训练任务动态结合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hps = {\n",
    "         'seed': 0,\n",
    "         'learning-rate': 0.0002,\n",
    "         'epochs': 15,\n",
    "         'dataset': 'qmnist',\n",
    "         'pin-memory': 1,\n",
    "         'beta1': 0.5,\n",
    "         'nc': 1,\n",
    "         'nz': 100,\n",
    "         'ngf': 64,\n",
    "         'ndf': 64,\n",
    "         'batch-size': 64,\n",
    "         'sample-interval': 100,\n",
    "         'log-interval': 20,\n",
    "     }\n",
    "\n",
    "\n",
    "print(json.dumps(hps, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sagemaker.pytorch 包里的 ```PyTorch``` 类是基于 PyTorch 框架的模型拟合器，可以用来创建、执行训练任务，还可以对训练完的模型进行部署。参数列表中， ``train_instance_type`` 用来指定CPU或者GPU实例类型，训练脚本和包括模型代码所在的目录通过 ``source_dir`` 指定，训练脚本文件名必须通过 ``entry_point`` 明确定义。这些参数将和其余参数一起被传递给训练任务，他们决定了训练任务的运行环境和模型训练时参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                        entry_point='train.py',\n",
    "                        source_dir='dcgan',\n",
    "                        output_path=s3_model_artifacts_location,\n",
    "                        code_location=s3_custom_code_upload_location,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.c5.large',\n",
    "                        train_use_spot_instances=True,\n",
    "                        train_max_wait=86400,\n",
    "                        framework_version='1.4.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请特别注意 ``train_use_spot_instances`` 参数，``True`` 值代表您希望优先使用 SPOT 实例。由于机器学习训练工作通常需要大量计算资源长时间运行，善用 SPOT 可以帮助您实现有效的成本控制，SPOT 实例价格可能是按需实例价格的 20% 到 60%，依据选择实例类型、区域、时间不同实际价格有所不同。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您已经创建了 PyTorch 对象，下面可以用它来拟合预先存在 Amazon S3 上的数据了。下面的指令将执行训练任务，训练数据将以名为 **QMNIST** 的输入通道的方式导入训练环境。训练开始执行过程中，Amazon S3 上的训练数据将被下载到模型训练环境的本地文件系统，训练脚本 ```train.py``` 将从本地磁盘加载数据进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "estimator.fit({\"QMNIST\": s3_data_location}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge ipywidgets nodejs\n",
    "!conda update -y tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: PyTorch deployments using TorchServe and Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we’ll show you how you can build a TorchServe container and host it using Amazon SageMaker. With Amazon SageMaker hosting you get a fully-managed hosting experience. Just specify the type of instance, and the maximum and minimum number desired, and SageMaker takes care of the rest.\n",
    "\n",
    "With a few lines of code, you can ask Amazon SageMaker to launch the instances, download your model from Amazon S3 to your TorchServe container, and set up the secure HTTPS endpoint for your application. On the client side, get prediction with a simple API call to this secure endpoint backed by TorchServe.\n",
    "\n",
    "Code, configuration files, Jupyter notebooks and Dockerfiles used in this example are available here:\n",
    "https://github.com/shashankprasanna/torchserve-examples.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For CPU\n",
    "!conda install -y -c pytorch -c powerai pytorch=1.5 torchtext torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For GPU\n",
    "!conda install -y -c pytorch -c powerai pytorch=1.5 torchtext torchvision cudatoolkit=10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade sagemaker awscli boto3 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the TorchServe repository and install torch-model-archiver\n",
    "\n",
    "You'll use `torch-model-archiver` to create a model archive file (.mar). The .mar model archive file contains model checkpoints along with it’s `state_dict` (dictionary object that maps each layer to its parameter tensor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a boto3 session and get specify a role with SageMaker access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = name_from_base('byos-pytorch-gan')\n",
    "prefix = job_name + '/pgan'\n",
    "\n",
    "input_shape = [1, 512]\n",
    "data_shape = '{\"input0\":[1, 512]}'\n",
    "\n",
    "model_prefix = 'pgan'\n",
    "model_folder = f'./tmp/{model_prefix}'\n",
    "\n",
    "ecr_repository_name = f\"{model_prefix}\".replace('_', '-')\n",
    "\n",
    "print(ecr_repository_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import VGG19 from TorchVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import [VGG19_bn](https://arxiv.org/pdf/1409.1556.pdf) model from TorchVision and create a model artifact `model.tar.gz`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a PyTorch model and create a TorchServe archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "\n",
    "# https://dl.fbaipublicfiles.com/gan_zoo/PGAN/celebaHQ_s6_i80000-6196db68.pth\n",
    "# trained on high-quality celebrity faces \"celebA\" dataset\n",
    "# this model outputs 512 x 512 pixel images\n",
    "pgan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                       'PGAN', model_name='celebAHQ-512',\n",
    "                       pretrained=True, useGPU=use_gpu)\n",
    "# this model outputs 256 x 256 pixel images\n",
    "# model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "#                        'PGAN', model_name='celebAHQ-256',\n",
    "#                        pretrained=True, useGPU=use_gpu)\n",
    "\n",
    "model = pgan.netG\n",
    "print(pgan.getSize())\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {model_folder}\n",
    "\n",
    "torch.save(model.state_dict(), f\"{model_folder}/pgan-celebAHQ-512.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_file = \"model.py\"\n",
    "model_def_path = os.path.join(\"./pgan/\", model_file)\n",
    "if not os.path.isfile(model_def_path):\n",
    "    raise RuntimeError(\"Missing the model.py file\")\n",
    "\n",
    "state_dict = torch.load(f\"{model_folder}/pgan-celebAHQ-512.pth\", map_location=\"cpu\")\n",
    "\n",
    "from pgan.progressive_conv_net import GNet\n",
    "model = GNet(512, 512)\n",
    "model.addScale(512)\n",
    "model.addScale(512)\n",
    "model.addScale(512)\n",
    "model.addScale(256)\n",
    "model.addScale(128)\n",
    "model.addScale(64)\n",
    "model.addScale(32)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(f\"{model_folder}/pgan-celebAHQ-512.pth\")\n",
    "model.load_state_dict(model_state_dict) # ,strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_images = 8\n",
    "noise, _ = pgan.buildNoiseData(num_images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_images = model(noise)\n",
    "\n",
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot these images using torchvision and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1),\n",
    "                                   scale_each=True, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torch-model-archiver --model-name pgan-celebAHQ-512 --export-path {model_folder} \\\n",
    "            --version 1.0 --serialized-file {model_folder}/pgan-celebAHQ-512.pth \\\n",
    "            --handler pgan/handler.py \\\n",
    "            --force \\\n",
    "            --model-file pgan/model.py \\\n",
    "            --extra-files pgan/custom_layers.py,pgan/mini_batch_stddev_module.py,pgan/utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(f\"{model_folder}/pgan-celebAHQ-512.tar.gz\", 'w:gz') as f:\n",
    "    f.add(f\"{model_folder}/pgan-celebAHQ-512.mar\", arcname=\"pgan-celebAHQ-512.mar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the generated densenet161.mar archive file to Amazon S3\n",
    "Create a compressed tar.gz file from the densenet161.mar file since Amazon SageMaker expects that models are in a tar.gz file. \n",
    "Uploads the model to your default Amazon SageMaker S3 bucket under the models directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = sess.upload_data(path=f\"{model_folder}/pgan-celebAHQ-512.tar.gz\",\n",
    "                              key_prefix=f\"{prefix}/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Amazon ECR registry\n",
    "Create a new docker container registry for your torchserve container images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "!pygmentize -l docker \"docker/Dockerfile.torchserve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "!pygmentize -l bash \"docker/build_and_push.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a TorchServe Docker container and push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "%cd docker\n",
    "!sh build_and_push.sh pytorch-torchserve Dockerfile.torchserve #$account_id $region $ecr_repository_name\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "container_image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/pytorch-torchserve:latest'\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy endpoint and make prediction using Amazon SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "sm_model_name = f'model-{model_prefix}-'.replace('_', '-') \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# model = PyTorchModel(model_data=s3_model_path, \n",
    "#                      image=container_image_uri,\n",
    "#                      role=role,\n",
    "#                      predictor_cls=RealTimePredictor,\n",
    "#                      name=sm_model_name,\n",
    "#                      entry_point='script.py',\n",
    "#                      framework_version=\"1.5\",\n",
    "#                      sagemaker_session=sess)\n",
    "\n",
    "\n",
    "model = Model(model_data=s3_model_path, \n",
    "                 image=container_image_uri,\n",
    "                 role=role,\n",
    "                 predictor_cls=RealTimePredictor,\n",
    "                 name=sm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "endpoint_name = f'endpoint-{model_prefix}-'.replace('_', '-') \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.c5.xlarge',\n",
    "                            initial_instance_count=1,\n",
    "                            endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the TorchServe hosted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Let's test with a cat image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "num_images = 5\n",
    "noise, _ = pgan.buildNoiseData(num_images)\n",
    "x = noise.numpy()\n",
    "print(x.shape)\n",
    "x = x.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(data=x)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 4\n",
    "noise, _ = pgan.buildNoiseData(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generated_images = pgan.test(noise)\n",
    "\n",
    "# let's plot these images using torchvision and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1),\n",
    "                                   scale_each=True, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 pytorch_GAN_zoo/train.py StyleGAN -c pytorch_GAN_zoo/config_celebaHQ.json --restart -n style_gan_celeba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
