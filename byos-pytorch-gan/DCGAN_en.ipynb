{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build GAN (Generative Adversarial Networks) with PyTorch and SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many public datasets on the Internet, which are very helpful for machine learning engineering and scientific research, such as algorithm study and evaluation. We will use MNIST dataset, which is a handwritten digits dataset, we will use it to train a GAN model, and eventually generate some fake \"handwritten\" digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "Upgrade packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip \n",
    "!pip install --upgrade sagemaker awscli boto3 pandas Pillow==7.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following commands for ```SageMaker Studio``` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/ml-on-aws/byos-pytorch-gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "PyTorch framework has a torchvision.datasets package, which provides MNIST dataset, you may use the following commands to download MNIST dataset to local storage, for late use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataroot = './data'\n",
    "\n",
    "trainset = datasets.MNIST(root=dataroot, train=True, download=True)\n",
    "testset = datasets.MNIST(root=dataroot, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "SageMaker SDK will create a default Amazon S3 bucket for you to access various files and data, that you may need in the machine learning engineering lifecycle. We can get the name of this bucket through the default_bucket method of the sagemaker.session.Session class in the SageMaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to save your custom code in tar.gz format.\n",
    "s3_custom_code_upload_location = f's3://{bucket}/customcode/byos-pytorch-gan'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "s3_model_artifacts_location = f's3://{bucket}/artifacts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SageMaker SDK provides tools for operating AWS services. For example, the S3Downloader class is used to download objects in S3, and the S3Uploader is used to upload local files to S3. You will upload the dataset files to Amazon S3 for model training. During model training, we do not download data from the Internet to avoid network latency caused by fetching data from the Internet, and at the same time avoiding possible security risks due to direct access to the Internet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader as s3up\n",
    "\n",
    "s3_data_location = s3up.upload(os.path.join(dataroot, \"MNIST\"), f\"s3://{bucket}/data/mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per sagemaker.get_execution_role() method, the notebook can get the role pre-assigned to the notebook instance. This role will be used to obtain training resources, such as downloading training framework images, allocating Amazon EC2 instances, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters, that used in the model training tasks, can be defined in the notebook so that it is separated from the algorithm and training code. The hyperparameters are passed in when the training task is created and dynamically combined with the training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hps = {\n",
    "         'seed': 0,\n",
    "         'learning-rate': 0.0002,\n",
    "         'epochs': 18,\n",
    "         'dataset': 'mnist',\n",
    "         'pin-memory': 1,\n",
    "         'beta1': 0.5,\n",
    "         'nc': 1,\n",
    "         'nz': 100,\n",
    "         'ngf': 28,\n",
    "         'ndf': 28,\n",
    "         'batch-size': 128,\n",
    "         'sample-interval': 100,\n",
    "         'log-interval': 20,\n",
    "     }\n",
    "\n",
    "\n",
    "str_hps = json.dumps(hps, indent = 4)\n",
    "print(str_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```PyTorch``` class from sagemaker.pytorch package, is an estimator for PyTorch framework, it can be used to create and execute training tasks, as well as to deploy trained models. In the parameter list, ``train_instance_type`` is used to specify the instance type, such as CPU or GPU instances. The directory containing training script and the model code are specified by ``source_dir``, and the training script file name must be clearly defined by ``entry_point``. These parameters will be passed to the training task along with other parameters, and they determine the environment settings of the training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                        entry_point='train.py',\n",
    "                        source_dir='networks/DCGAN',\n",
    "                        output_path=s3_model_artifacts_location,\n",
    "                        code_location=s3_custom_code_upload_location,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.p3.2xlarge',\n",
    "                        train_use_spot_instances=True,\n",
    "                        train_max_wait=86400,\n",
    "                        framework_version='1.5.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hps,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please pay special attention to the ``train_use_spot_instances`` parameter. The value of ``True`` means that you want to use SPOT instances first. Since machine learning training usually requires a large amount of computing resources to run for a long time, leveraging SPOT instances can help you control your cost. The SPOT instances may save cost up to 90% of the on-demand instances, depending on the instance type, region, and time, the actual price might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have created a PyTorch object, and you can use it to fit pre-uploaded data on Amazon S3. The following command will initiate the training task, and the training data will be imported into the training environment in the form of an input channel named **MNIST**. When the training task starts, the training data was already downloaded from S3 to the local file system of the training instance, and the training script ```train.py``` will load the data from the local disk afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "estimator.fit({\"MNIST\": s3_data_location}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the training instance you choose, the training process may last from tens of minutes to several hours. It is recommended to set the ``wait`` parameter to ``False``, this option will detach the notebook from the training task. In scenarios with long training time and many training logs, it can prevent the notebook context from being lost due to network interruption or session timeout. After the notebook detached from the training task, the output will be temporarily invisible. You can execute the following code, and the notebook will obtain and resume the previous training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Attaching previous training session\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "attached_estimator = Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model was designed to leverage the GPU power to accelerate training, it will be much faster than training tasks on CPU instances. For example, the p3.2xlarge instance will take about 15 minutes, while the c5.xlarge instance may take more than 6 hours. The current model does not support distributed and parallel training, so multi-instance and multi-CPU/GPU will not bring extra benefits in training speed boosting.\n",
    "\n",
    "When the training completes, the trained model will be uploaded to S3. The upload location is specified by the `output_path` parameter provided when creating the `PyTorch` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "### Model verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "You will download the trained model from Amazon S3 to the local file system of the instance where the notebook is located. The following code will load the model, and then generate a picture with a random number as input, then display picture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "last_artifact_location = s3_model_artifacts_location + training_job_name\n",
    "\n",
    "last_model_url = get_object_path_by_filename(last_artifact_location, 'model.tar.gz')\n",
    "last_output_url = get_object_path_by_filename(last_artifact_location, 'output.tar.gz')\n",
    "\n",
    "print(last_model_url)\n",
    "print(last_output_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader as s3down\n",
    "\n",
    "!rm -rf ./tmp/* ./model/*\n",
    "s3down.download(last_model_url, './tmp')\n",
    "s3down.download(last_output_url, './tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "!tar -zxf tmp/model.tar.gz -C ./tmp\n",
    "!tar -zxf tmp/output.tar.gz -C ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "Execute the following instructions to load the trained model, and generate a set of \"handwritten\" digitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from networks.DCGAN.model import Generator\n",
    "from networks.DCGAN.model_tools import generate_fake_handwriting\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'nz': hps['nz'], 'nc': hps['nc'], 'ngf': hps['ngf']}\n",
    "model = helper.load_model(\"./tmp/generator_state.pth\", model_cls=Generator, params=params, device=device, strict=False)\n",
    "img = generate_fake_handwriting(model, num_images=64, nz=hps['nz'], device=device)\n",
    "\n",
    "plt.imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss tracking (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "<img align=left src=\"tmp/loss_tracking.png\" type=\"image/png\" width=600>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake image samples looping (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "fake_files = []\n",
    "for root, dirs, files in os.walk(\"tmp\", topdown=False):\n",
    "    for name in files:\n",
    "        if not root == \"tmp\":\n",
    "            continue\n",
    "        if not name[:4] == \"fake\":\n",
    "            continue\n",
    "        if not name[-9:] == \"b0000.png\":\n",
    "            continue\n",
    "        fake_files.append(name)\n",
    "    for name in dirs:\n",
    "        continue\n",
    "        print(os.path.join(root, name))\n",
    "\n",
    "fake_files.sort()\n",
    "\n",
    "images = []\n",
    "for file in fake_files:\n",
    "    im = Image.open(f'tmp/{file}')\n",
    "    images.append(im)\n",
    "\n",
    "images[0].save('tmp/gan.gif',\n",
    "               save_all=True, append_images=images[1:], optimize=False, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "<img align=left src=\"tmp/gan.gif\" type=\"image/gif\" width=300>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:cn-northwest-1:390780980154:image/pytorch-1.4-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
