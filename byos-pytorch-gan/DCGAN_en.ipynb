{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build GAN (Generative Adversarial Networks) with PyTorch and SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many public datasets on the Internet, which are very helpful for machine learning engineering and scientific research, such as algorithm study and evaluation. We will use MNIST dataset, which is a handwritten digits dataset, we will use it to train a GAN model, and eventually generate some fake \"handwritten\" digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "Upgrade packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip \n",
    "!pip install --upgrade sagemaker awscli boto3 pandas Pillow==7.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following commands for ```SageMaker Studio``` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/ml-on-aws/byos-pytorch-gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "PyTorch framework has a torchvision.datasets package, which provides MNIST dataset, you may use the following commands to download MNIST dataset to local storage, for late use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataroot = './data'\n",
    "\n",
    "trainset = datasets.MNIST(root=dataroot, train=True, download=True)\n",
    "testset = datasets.MNIST(root=dataroot, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "SageMaker SDK will create a default Amazon S3 bucket for you to access various files and data, that you may need in the machine learning engineering lifecycle. We can get the name of this bucket through the default_bucket method of the sagemaker.session.Session class in the SageMaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to save your custom code in tar.gz format.\n",
    "s3_custom_code_upload_location = f's3://{bucket}/customcode/byos-pytorch-gan'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "s3_model_artifacts_location = f's3://{bucket}/artifacts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SageMaker SDK provides tools for operating AWS services. For example, the S3Downloader class is used to download objects in S3, and the S3Uploader is used to upload local files to S3. You will upload the dataset files to Amazon S3 for model training. During model training, we do not download data from the Internet to avoid network latency caused by fetching data from the Internet, and at the same time avoiding possible security risks due to direct access to the Internet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader as s3up\n",
    "\n",
    "s3_data_location = s3up.upload(os.path.join(dataroot, \"MNIST\"), f\"s3://{bucket}/data/mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per sagemaker.get_execution_role() method, the notebook can get the role pre-assigned to the notebook instance. This role will be used to obtain training resources, such as downloading training framework images, allocating Amazon EC2 instances, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters, that used in the model training tasks, can be defined in the notebook so that it is separated from the algorithm and training code. The hyperparameters are passed in when the training task is created and dynamically combined with the training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hps = {\n",
    "         'seed': 0,\n",
    "         'learning-rate': 0.0002,\n",
    "         'epochs': 18,\n",
    "         'dataset': 'mnist',\n",
    "         'pin-memory': 1,\n",
    "         'beta1': 0.5,\n",
    "         'nc': 1,\n",
    "         'nz': 100,\n",
    "         'ngf': 28,\n",
    "         'ndf': 28,\n",
    "         'batch-size': 128,\n",
    "         'sample-interval': 100,\n",
    "         'log-interval': 20,\n",
    "     }\n",
    "\n",
    "\n",
    "str_hps = json.dumps(hps, indent = 4)\n",
    "print(str_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```PyTorch``` class from sagemaker.pytorch package, is an estimator for PyTorch framework, it can be used to create and execute training tasks, as well as to deploy trained models. In the parameter list, ``train_instance_type`` is used to specify the instance type, such as CPU or GPU instances. The directory containing training script and the model code are specified by ``source_dir``, and the training script file name must be clearly defined by ``entry_point``. These parameters will be passed to the training task along with other parameters, and they determine the environment settings of the training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                        entry_point='train.py',\n",
    "                        source_dir='networks/DCGAN',\n",
    "                        output_path=s3_model_artifacts_location,\n",
    "                        code_location=s3_custom_code_upload_location,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.p3.2xlarge',\n",
    "                        train_use_spot_instances=True,\n",
    "                        train_max_wait=86400,\n",
    "                        framework_version='1.5.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hps,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请特别注意 ``train_use_spot_instances`` 参数，``True`` 值代表您希望优先使用 SPOT 实例。由于机器学习训练工作通常需要大量计算资源长时间运行，善用 SPOT 可以帮助您实现有效的成本控制，SPOT 实例价格可能是按需实例价格的 20% 到 60%，依据选择实例类型、区域、时间不同实际价格有所不同。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您已经创建了 PyTorch 对象，下面可以用它来拟合预先存在 Amazon S3 上的数据了。下面的指令将执行训练任务，训练数据将以名为 **MNIST** 的输入通道的方式导入训练环境。训练开始执行过程中，Amazon S3 上的训练数据将被下载到模型训练环境的本地文件系统，训练脚本 ```train.py``` 将从本地磁盘加载数据进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "estimator.fit({\"MNIST\": s3_data_location}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据您选择的训练实例不同，训练过程中可能持续几十分钟到几个小时不等。建议设置 ``wait`` 参数为 ``False`` ，这个选项将使笔记本与训练任务分离，在训练时间长、训练日志多的场景下，可以避免笔记本上下文因为网络中断或者会话超时而丢失。训练任务脱离笔记本后，输出将暂时不可见，可以执行如下代码，笔记本将获取并载入此前的训练回话，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Attaching previous training session\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "attached_estimator = Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于的模型设计考虑到了GPU对训练加速的能力，所以用GPU实例训练会比CPU实例快一些，例如，p3.2xlarge 实例大概需要15分钟左右，而 c5.xlarge 实例则可能需要6小时以上。目前模型不支持分布、并行训练，所以多实例、多CPU/GPU并不会带来更多的训练速度提升。\n",
    "\n",
    "训练完成后，模型将被上传到 Amazon S3 里，上传位置由创建 `PyTorch` 对象时提供的 `output_path` 参数指定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "### 模型的验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "您将从 Amazon S3 下载经过训练的模型到笔记本所在实例的本地文件系统，下面的代码将载入模型，然后输入一个随机数，获得推理结果，以图片形式展现出来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "last_artifact_location = s3_model_artifacts_location + training_job_name\n",
    "\n",
    "last_model_url = get_object_path_by_filename(last_artifact_location, 'model.tar.gz')\n",
    "last_output_url = get_object_path_by_filename(last_artifact_location, 'output.tar.gz')\n",
    "\n",
    "print(last_model_url)\n",
    "print(last_output_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader as s3down\n",
    "\n",
    "!rm -rf ./tmp/* ./model/*\n",
    "s3down.download(last_model_url, './tmp')\n",
    "s3down.download(last_output_url, './tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "!tar -zxf tmp/model.tar.gz -C ./tmp\n",
    "!tar -zxf tmp/output.tar.gz -C ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isConfigCell": true
   },
   "source": [
    "执行如下指令加载训练好的模型，并通过这个模型产生一组『手写』数字字体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from networks.DCGAN.model import Generator\n",
    "from networks.DCGAN.model_tools import generate_fake_handwriting\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'nz': hps['nz'], 'nc': hps['nc'], 'ngf': hps['ngf']}\n",
    "model = helper.load_model(\"./tmp/generator_state.pth\", model_cls=Generator, params=params, device=device, strict=False)\n",
    "img = generate_fake_handwriting(model, num_images=64, nz=hps['nz'], device=device)\n",
    "\n",
    "plt.imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss tracking (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "<img align=left src=\"tmp/loss_tracking.png\" type=\"image/png\" width=600>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake image samples looping (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "fake_files = []\n",
    "for root, dirs, files in os.walk(\"tmp\", topdown=False):\n",
    "    for name in files:\n",
    "        if not root == \"tmp\":\n",
    "            continue\n",
    "        if not name[:4] == \"fake\":\n",
    "            continue\n",
    "        if not name[-9:] == \"b0000.png\":\n",
    "            continue\n",
    "        fake_files.append(name)\n",
    "    for name in dirs:\n",
    "        continue\n",
    "        print(os.path.join(root, name))\n",
    "\n",
    "fake_files.sort()\n",
    "\n",
    "images = []\n",
    "for file in fake_files:\n",
    "    im = Image.open(f'tmp/{file}')\n",
    "    images.append(im)\n",
    "\n",
    "images[0].save('tmp/gan.gif',\n",
    "               save_all=True, append_images=images[1:], optimize=False, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "<img align=left src=\"tmp/gan.gif\" type=\"image/gif\" width=300>\n",
    "</div>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:cn-northwest-1:390780980154:image/pytorch-1.4-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
